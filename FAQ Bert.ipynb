{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "An8oY5l9CPod"
   },
   "source": [
    "# **FAQ Classification using BERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2S0M53hWCUtU"
   },
   "source": [
    "Classifying UGC as FAQ or Not FAQ using Google's BERT Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWVcAXqBCbTl"
   },
   "source": [
    "Author: Shreyash Gupta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFRzwYupCeBM"
   },
   "source": [
    "Organization: IndiaMART InterMESH Pvt. Ltd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Executed on Google Colab with GPU environment_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kbbL71TECjf0"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71l6wZtvCozs"
   },
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3dziOYtCuu6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mCyV7EJCsGy"
   },
   "source": [
    "Mounting to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "ZSqDIHEmCO0C",
    "outputId": "6ceac670-fa6e-4f88-ba4f-e2b35acc6cdf"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gON5rA-gC92r"
   },
   "source": [
    "Reading training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifyNPQneDDxD"
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel(\"/content/gdrive/My Drive/Colab Notebooks/faq_bert_text.xlsx\")\n",
    "test = pd.read_excel(\"/content/gdrive/My Drive/Colab Notebooks/faq_bert_text_test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnVsjOF4ETqk"
   },
   "source": [
    "Defiining Data Column and Label Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EoFUVun_EXYb"
   },
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'Question Title'\n",
    "LABEL_COLUMN = 'Remarks'\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFkuvph7EfTr"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtT0Z7bCE3oy"
   },
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "p4N8_YwqE3xq",
    "outputId": "374077ea-e344-4d88-e59b-eac7ec46aa36"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfPqe-RrEiXi"
   },
   "source": [
    "Lowercasing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "4kUJzg59Eiry",
    "outputId": "bd502f9a-24db-4937-9fc7-73d099d3f4b4"
   },
   "outputs": [],
   "source": [
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"], tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file = vocab_file, do_lower_case = do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mokFAVjFGWi"
   },
   "source": [
    "### **Extracting train and test features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_HF4W93IG9c"
   },
   "source": [
    "Creating examples of BERT input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJoZZZ3EICgZ"
   },
   "outputs": [],
   "source": [
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid = None, text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid = None, text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhXvg3wyIO7m"
   },
   "source": [
    "Extracting train and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "SxqN4oOWFPui",
    "outputId": "5d1ee407-9ce8-4b07-f7eb-394a61a1c8d8"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 128\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSdsE20SJqi9"
   },
   "source": [
    "# **Creating the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXZYbLLJKBjF"
   },
   "source": [
    "Defining a function to create a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u02zh8r-JtWF"
   },
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
    "\n",
    "  bert_module = hub.Module(BERT_MODEL_HUB, trainable=True)\n",
    "  bert_inputs = dict(input_ids = input_ids, input_mask = input_mask, segment_ids = segment_ids)\n",
    "  bert_outputs = bert_module(inputs = bert_inputs, signature = \"tokens\", as_dict = True)\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  output_weights = tf.get_variable(\"output_weights\", [num_labels, hidden_size], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "  output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "    \n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b = True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis = -1)\n",
    "\n",
    "    one_hot_labels = tf.one_hot(labels, depth = num_labels, dtype = tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis = -1, output_type = tf.int32))\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs)\n",
    "\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis = -1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mrr6bVjzK428"
   },
   "source": [
    "Wrapping model in a model function builder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fMUnTGJuK5CL"
   },
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "  \n",
    "  def model_fn(features, labels, mode, params):\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    if not is_predicting:\n",
    "      (loss, predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer( loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu = False)\n",
    "\n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        f1_score = tf.contrib.metrics.f1_score(label_ids, predicted_labels)\n",
    "        auc = tf.metrics.auc(label_ids, predicted_labels)\n",
    "        recall = tf.metrics.recall(label_ids, predicted_labels)\n",
    "        precision = tf.metrics.precision(label_ids, predicted_labels) \n",
    "        true_pos = tf.metrics.true_positives(label_ids, predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(label_ids, predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(label_ids, predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(label_ids, predicted_labels)\n",
    "        \n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"auc\": auc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg\n",
    "        }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels\n",
    "      }\n",
    "  \n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ty8SAfDUL2KK"
   },
   "source": [
    "Defining variables and parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXc159XxL2Wj"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "WARMUP_PROPORTION = 0.1\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "OUTPUT_DIR = \"/content/gdrive/My Drive/Colab Notebooks/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91MgQEZQMnbB"
   },
   "source": [
    "Computing number of training and warmup steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sE-Xap6kMmM8"
   },
   "outputs": [],
   "source": [
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YjdqM-y8MmGZ"
   },
   "source": [
    "Defining the run congifuration for estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8SU78rsM6oZ"
   },
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig(model_dir = OUTPUT_DIR, save_summary_steps = SAVE_SUMMARY_STEPS, save_checkpoints_steps = SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFXP6rmINQFq"
   },
   "source": [
    "Creating the model function and estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-Dr_8o4NQVJ"
   },
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(num_labels = len(label_list), learning_rate = LEARNING_RATE, num_train_steps = num_train_steps, num_warmup_steps = num_warmup_steps)\n",
    "estimator = tf.estimator.Estimator(model_fn = model_fn, config = run_config, params = {\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-a6OPsldNhcR"
   },
   "source": [
    "Creating the training input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76Tp5dLkNhtB"
   },
   "outputs": [],
   "source": [
    "train_input_fn = bert.run_classifier.input_fn_builder(features = train_features, seq_length = MAX_SEQ_LENGTH, is_training = True, drop_remainder = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HT8LiA0qNp4i"
   },
   "source": [
    "# **Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPs1BgrlPgOg"
   },
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpFxlHUrN8QY"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6CcJI5HKN8gJ"
   },
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "XK0REliFNqCB",
    "outputId": "057da7f2-ea8a-44a6-b776-55b2cdad3a3f"
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "estimator.train(input_fn = train_input_fn, max_steps = num_train_steps)\n",
    "print(\"Training time: \",datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NR14BClXOM9Q"
   },
   "source": [
    "# **Testing the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cn_lG3bgPx8f"
   },
   "source": [
    "Creating the test input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIJ0htrIONMw"
   },
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(features = test_features, seq_length = MAX_SEQ_LENGTH, is_training = False, drop_remainder = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "je5HI3Z-Ob0X"
   },
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "5NrHAfUrOcCY",
    "outputId": "b76e84d1-80df-4f21-831f-5ba9996cb559"
   },
   "outputs": [],
   "source": [
    "estimator.evaluate(input_fn = test_input_fn, steps = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8B7jdaOYOqj4"
   },
   "source": [
    "# **Predicting labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ny5XB5a_P7Vf"
   },
   "source": [
    "Defining prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RbClFlfjOqvw"
   },
   "outputs": [],
   "source": [
    "def getPrediction(in_sentences):\n",
    "  labels = [\"Not FAQ\", \"FAQ\"]\n",
    "  input_examples = [run_classifier.InputExample(guid = \"\", text_a = x, text_b = None, label = 0) for x in in_sentences]\n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  predict_input_fn = run_classifier.input_fn_builder(features = input_features, seq_length = MAX_SEQ_LENGTH, is_training = False, drop_remainder = False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SVPhgabO0z4"
   },
   "source": [
    "Creating a list of input test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oke6ZWnLO1CP"
   },
   "outputs": [],
   "source": [
    "pred_sentences = test[\"Question Title\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrjXPW4gO6AH"
   },
   "source": [
    "Getting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-wK-Ya49O6LX"
   },
   "outputs": [],
   "source": [
    "predictions = getPrediction(pred_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9z5G2smfO8yP"
   },
   "source": [
    "Creating Data Frame for predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2dCJfZkkQ0I"
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(columns = [\"Question Title\",\"Actual\", \"Predicted\"])\n",
    "pred[\"Question Title\"] = [predictions[i][0] for i in range(len(predictions))]\n",
    "test[\"Remarks\"].replace({0 : \"Not FAQ\", 1: \"FAQ\"}, inplace = True)\n",
    "pred[\"Actual\"] = test[\"Remarks\"]\n",
    "pred[\"Predicted\"] = [predictions[i][2] for i in range(len(predictions))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-jBaXgeFlwlG"
   },
   "source": [
    "Exporting result to excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPngT92KkriS"
   },
   "outputs": [],
   "source": [
    "pred.to_excel(\"/content/gdrive/My Drive/Colab Notebooks/faq_bert_predictions.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FAQ Bert",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
