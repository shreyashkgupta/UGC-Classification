{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo Vectorization for FAQ Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program to create ELMo vectors for training and testing data. Using these vectors, different models are analyzed against 4 performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Shreyash Gupta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organization: IndiaMART InterMESH Pvt. Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train = pd.read_excel(\"faq_train_updated.xlsx\")\n",
    "faq_test = pd.read_excel(\"faq_test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train['Remarks'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_test['Remarks'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train['cleanQT'] = faq_train['Question Title'].str.replace(\"[0-9]\",\" \")\n",
    "faq_test['cleanQT'] = faq_test['Question Title'].str.replace(\"[0-9]\",\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Remove special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_symbols = '!@#$%^&*()_-+=[]\\{}|;\",.<>/?~:\\\"'\n",
    "faq_train['cleanQT'] = faq_train['cleanQT'].apply(lambda rss: ''.join(ch for ch in rss if ch not in set(special_symbols)))\n",
    "faq_test['cleanQT'] = faq_test['cleanQT'].apply(lambda rss: ''.join(ch for ch in rss if ch not in set(special_symbols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert all characters to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train['cleanQT'] = faq_train['cleanQT'].str.lower()\n",
    "faq_test['cleanQT'] = faq_test['cleanQT'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Remove white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_test['cleanQT'] = faq_test['cleanQT'].apply(lambda rws: ' '.join(rws.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing differences before/after preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data\")\n",
    "print(faq_train.sample(5))\n",
    "print(\"Testing data\")\n",
    "print(faq_test.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing ELMo vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the ELMo module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function for creating ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_vectors(text):\n",
    "    embeddings = elmo(text.tolist(),signature = \"default\", as_dict = True)[\"elmo\"]\n",
    "    with tf.compat.v1.Session() as session:\n",
    "        session.run(tf.compat.v1.global_variables_initializer())\n",
    "        session.run(tf.compat.v1.tables_initializer())\n",
    "        return session.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into batches for better computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_start_time = time.time()\n",
    "faq_train_list = [faq_train[i:i+100] for i in range(0,faq_train.shape[0],100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_extraction_start_time = time.time()\n",
    "faq_elmo_train = [elmo_vectors(x['cleanQT']) for x in faq_train_list]\n",
    "elmo_extraction_end_time = time.time()\n",
    "print(\"Total extraction time for ELMo vectors: {} seconds\".format(elmo_extraction_end_time - elmo_extraction_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking dimensions of ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training: \",len(faq_elmo_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenatening all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_concat_start_time = time.time()\n",
    "elmo_faq_train = np.concatenate(faq_elmo_train, axis = 0)\n",
    "elmo_end_time = elmo_concat_end_time = time.time()\n",
    "print(\"Total concatenation time: {} seconds\".format(elmo_concat_end_time - elmo_concat_start_time))\n",
    "print(\"Total time for ELMo vector extraction: {} seconds\".format(elmo_end_time - elmo_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving output to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out_train = open(\"elmo_faq_train_updated_11072019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_faq_train, pickle_out_train)\n",
    "pickle_out_train.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading ELMo vectors pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in_train = open(\"elmo_faq_train_upadated_11072019.pickle\",\"rb\")\n",
    "pickle_in_test = open(\"elmo_faq_test_072019.pickle\",\"rb\")\n",
    "elmo_faq_train = pickle.load(pickle_in_train)\n",
    "elmo_faq_test = pickle.load(pickle_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(elmo_faq_train)\n",
    "y = faq_train['Remarks']\n",
    "xvalid = pd.DataFrame(elmo_faq_test)\n",
    "yvalid = faq_test['Remarks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE(random_state = 1)\n",
    "xtrain, ytrain = smt.fit_sample(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buidling a logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_start_time = time.time()\n",
    "regressor = LogisticRegression()\n",
    "regressor.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_val_lr = regressor.predict(xvalid)\n",
    "lr_end_time = time.time()\n",
    "print(\"Total time spent on LR: {} seconds\".format(lr_end_time - lr_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_lr,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_lr,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_lr,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_start_time = time.time()\n",
    "nbclassifier = GaussianNB()\n",
    "nbclassifier.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_nb = nbclassifier.predict(xvalid)\n",
    "nb_end_time = time.time()\n",
    "print(\"Total time spent on NB: {} seconds\".format(nb_end_time - nb_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_nb,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_nb,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_nb,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Linear SVM (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_start_time = time.time()\n",
    "sgdclassifier = SGDClassifier(random_state = 1)\n",
    "sgdclassifier.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_sgd = sgdclassifier.predict(xvalid)\n",
    "sgd_end_time = time.time()\n",
    "print(\"Total time spent on SVM (SGD): {} seconds\".format(sgd_end_time - sgd_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Linear SVM (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear SVM (SGD)\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buidling a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_start_time = time.time()\n",
    "rfc = RandomForestClassifier(random_state = 1)\n",
    "rfc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_rfc = rfc.predict(xvalid)\n",
    "rfc_end_time = time.time()\n",
    "print(\"Total time spent on RFC: {} seconds\".format(rfc_end_time - rfc_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RFC\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_rfc,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_rfc,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_rfc,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buidling a K Nearest Neighbors Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc_start_time = time.time()\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_knc = knc.predict(xvalid)\n",
    "knc_end_time = time.time()\n",
    "print(\"Total time spent on KNC: {} seconds\".format(knc_end_time - knc_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of K Nearest Neighbours Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNC\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_knc,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_knc,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_knc,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_knc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buidling a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc_start_time = time.time()\n",
    "dtc = DecisionTreeClassifier(random_state = 1)\n",
    "dtc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_dtc = dtc.predict(xvalid)\n",
    "dtc_end_time = time.time()\n",
    "print(\"Total time spent on DTC: {} seconds\".format(dtc_end_time - dtc_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DTC\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_dtc,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_dtc,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_dtc,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buidling a MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_start_time = time.time()\n",
    "mlp = MLPClassifier(random_state = 1)\n",
    "mlp.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_mlp = mlp.predict(xvalid)\n",
    "mlp_end_time = time.time()\n",
    "print(\"Total time spent on MLP: {} seconds\".format(mlp_end_time - mlp_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_mlp,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_mlp,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_mlp,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buidling a AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adab_start_time = time.time()\n",
    "adab = AdaBoostClassifier(random_state = 1)\n",
    "adab.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_adab = adab.predict(xvalid)\n",
    "adab_end_time = time.time()\n",
    "print(\"Total time spent on AdaBoost: {} seconds\".format(adab_end_time - adab_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AdaBoost\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_adab,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_adab,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_adab,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_adab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buidling a QDA Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda_start_time = time.time()\n",
    "qda = QuadraticDiscriminantAnalysis(random_state = 1)\n",
    "qda.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_qda = qda.predict(xvalid)\n",
    "qda_end_time = time.time()\n",
    "print(\"Total time spent on QDA: {} seconds\".format(qda_end_time - qda_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of QDA Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"QDA\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_qda,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_qda,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_qda,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_qda))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
