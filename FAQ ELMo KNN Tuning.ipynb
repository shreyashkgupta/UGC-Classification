{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of FAQ Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning of KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Shreyash Gupta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organization: IndiaMART InterMESH Pvt. Ltd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train = pd.read_excel(\"faq.xlsx\")\n",
    "faq_test = pd.read_excel(\"faq_test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train['Remarks'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_test['Remarks'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train['cleanQT'] = faq_train['Question Title'].str.replace(\"[0-9]\",\" \")\n",
    "faq_test['cleanQT'] = faq_test['Question Title'].str.replace(\"[0-9]\",\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Remove special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_symbols = '!@#$%^&*()_-+=[]\\{}|;\",.<>/?~:\\\"'\n",
    "faq_train['cleanQT'] = faq_train['cleanQT'].apply(lambda rss: ''.join(ch for ch in rss if ch not in set(special_symbols)))\n",
    "faq_test['cleanQT'] = faq_test['cleanQT'].apply(lambda rss: ''.join(ch for ch in rss if ch not in set(special_symbols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert all characters to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train['cleanQT'] = faq_train['cleanQT'].str.lower()\n",
    "faq_test['cleanQT'] = faq_test['cleanQT'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Remove white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_test['cleanQT'] = faq_test['cleanQT'].apply(lambda rws: ' '.join(rws.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing differences before/after preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data\")\n",
    "print(faq_train.sample(5))\n",
    "print(\"Testing data\")\n",
    "print(faq_test.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing ELMo vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the ELMo module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function for creating ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_vectors(text):\n",
    "    embeddings = elmo(text.tolist(),signature = \"default\", as_dict = True)[\"elmo\"]\n",
    "    with tf.compat.v1.Session() as session:\n",
    "        session.run(tf.compat.v1.global_variables_initializer())\n",
    "        session.run(tf.compat.v1.tables_initializer())\n",
    "        return session.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into batches for better computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_start_time = time.time()\n",
    "faq_train_list = [faq_train[i:i+100] for i in range(0,faq_train.shape[0],100)]\n",
    "faq_test_list = [faq_test[i:i+100] for i in range(0,faq_test.shape[0],100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_extraction_start_time = time.time()\n",
    "faq_elmo_train = [elmo_vectors(x['cleanQT']) for x in faq_train_list]\n",
    "faq_elmo_test = [elmo_vectors(x['cleanQT']) for x in faq_test_list]\n",
    "elmo_extraction_end_time = time.time()\n",
    "print(\"Total extraction time for ELMo vectors: {} seconds\".format(elmo_extraction_end_time - elmo_extraction_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking dimensions of ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training: \",len(faq_elmo_train))\n",
    "print(\"Testing: \",len(faq_elmo_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenatening all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_concat_start_time = time.time()\n",
    "elmo_faq_train = np.concatenate(faq_elmo_train, axis = 0)\n",
    "elmo_faq_test = np.concatenate(faq_elmo_test, axis = 0)\n",
    "elmo_end_time = elmo_concat_end_time = time.time()\n",
    "print(\"Total concatenation time: {} seconds\".format(elmo_concat_end_time - elmo_concat_start_time))\n",
    "print(\"Total time for ELMo vector extraction: {} seconds\".format(elmo_end_time - elmo_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving output to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out_train = open(\"elmo_faq_train_04062019.pickle\",\"wb\")\n",
    "pickle_out_test = open(\"elmo_faq_test_04062019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_faq_train, pickle_out_train)\n",
    "pickle.dump(elmo_faq_test,pickle_out_test)\n",
    "pickle_out_train.close()\n",
    "pickle_out_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading ELMo vectors pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in_train = open(\"elmo_faq_train_04062019.pickle\",\"rb\")\n",
    "pickle_in_test = open(\"elmo_faq_test_04062019.pickle\",\"rb\")\n",
    "elmo_faq_train = pickle.load(pickle_in_train)\n",
    "elmo_faq_test = pickle.load(pickle_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.DataFrame(elmo_faq_train)\n",
    "ytrain = faq_train['Remarks']\n",
    "xvalid = pd.DataFrame(elmo_faq_test)\n",
    "yvalid = faq_test['Remarks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buidling a K Nearest Neighbours Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc_start_time = time.time()\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_val_knc = knc.predict(xvalid)\n",
    "knc_end_time = time.time()\n",
    "print(\"Total time spent on KNC: {} seconds\".format(knc_end_time - knc_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of K Nearest Neighbours Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNC\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_knc,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_knc,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_knc,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_knc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_list = [3, 5, 10]\n",
    "w_list = ['uniform', 'distance']\n",
    "a_list = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "ls_list = [20, 30, 40]\n",
    "p_list = [1, 2]\n",
    "nj_list = [1, 2]\n",
    "pr = []\n",
    "r = []\n",
    "f1 = []\n",
    "mcc = []\n",
    "for nj in nj_list:\n",
    "    for p in p_list:\n",
    "        for ls in ls_list:\n",
    "            for a in a_list:\n",
    "                for w in w_list:\n",
    "                    for nn in nn_list:\n",
    "                        knnclassifier = KNeighborsClassifier(n_neighbors = nn, weights = w, algorithm = a, leaf_size = ls, p = p, n_jobs = nj)\n",
    "                        knnclassifier.fit(xtrain, ytrain)\n",
    "                        pred_val_knc = knc.predict(xvalid)\n",
    "                        print(\"KNC with nn - {}, w = {}, a - {}, ls = {}, p = {}, nj = {}\".format(nn, w, a, ls, p, nj))\n",
    "                        print(\"Precision: \",precision_score(yvalid,pred_val_knc,pos_label='FAQ'))\n",
    "                        pr.append(precision_score(yvalid,pred_val_knc,pos_label='FAQ'))\n",
    "                        print(\"Recall: \",recall_score(yvalid,pred_val_knc,pos_label='FAQ'))\n",
    "                        r.append(recall_score(yvalid,pred_val_knc,pos_label='FAQ'))\n",
    "                        print(\"F1 Score: \",f1_score(yvalid, pred_val_knc,pos_label='FAQ'))\n",
    "                        f1.append(f1_score(yvalid, pred_val_knc,pos_label='FAQ'))\n",
    "                        print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_knc))\n",
    "                        mcc.append(matthews_corrcoef(yvalid, pred_val_knc))\n",
    "                        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max precision: \",max(pr))\n",
    "print(\"Max recall: \",max(r))\n",
    "print(\"Max F1: \",max(f1))\n",
    "print(\"Max MCC: \",max(mcc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
