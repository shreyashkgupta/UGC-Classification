{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of FAQ Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning of Linear SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Shreyash Gupta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organization: IndiaMART InterMESH Pvt. Ltd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train = pd.read_excel(\"faq.xlsx\")\n",
    "faq_test = pd.read_excel(\"faq_test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train['Remarks'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_test['Remarks'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train['cleanQT'] = faq_train['Question Title'].str.replace(\"[0-9]\",\" \")\n",
    "faq_test['cleanQT'] = faq_test['Question Title'].str.replace(\"[0-9]\",\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Remove special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_symbols = '!@#$%^&*()_-+=[]\\{}|;\",.<>/?~:\\\"'\n",
    "faq_train['cleanQT'] = faq_train['cleanQT'].apply(lambda rss: ''.join(ch for ch in rss if ch not in set(special_symbols)))\n",
    "faq_test['cleanQT'] = faq_test['cleanQT'].apply(lambda rss: ''.join(ch for ch in rss if ch not in set(special_symbols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert all characters to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_train['cleanQT'] = faq_train['cleanQT'].str.lower()\n",
    "faq_test['cleanQT'] = faq_test['cleanQT'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Remove white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_test['cleanQT'] = faq_test['cleanQT'].apply(lambda rws: ' '.join(rws.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing differences before/after preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data\")\n",
    "print(faq_train.sample(5))\n",
    "print(\"Testing data\")\n",
    "print(faq_test.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preparing ELMo vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the ELMo module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function for creating ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_vectors(text):\n",
    "    embeddings = elmo(text.tolist(),signature = \"default\", as_dict = True)[\"elmo\"]\n",
    "    with tf.compat.v1.Session() as session:\n",
    "        session.run(tf.compat.v1.global_variables_initializer())\n",
    "        session.run(tf.compat.v1.tables_initializer())\n",
    "        return session.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into batches for better computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_start_time = time.time()\n",
    "faq_train_list = [faq_train[i:i+100] for i in range(0,faq_train.shape[0],100)]\n",
    "faq_test_list = [faq_test[i:i+100] for i in range(0,faq_test.shape[0],100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_extraction_start_time = time.time()\n",
    "faq_elmo_train = [elmo_vectors(x['cleanQT']) for x in faq_train_list]\n",
    "faq_elmo_test = [elmo_vectors(x['cleanQT']) for x in faq_test_list]\n",
    "elmo_extraction_end_time = time.time()\n",
    "print(\"Total extraction time for ELMo vectors: {} seconds\".format(elmo_extraction_end_time - elmo_extraction_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenatening all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_concat_start_time = time.time()\n",
    "elmo_faq_train = np.concatenate(faq_elmo_train, axis = 0)\n",
    "elmo_faq_test = np.concatenate(faq_elmo_test, axis = 0)\n",
    "elmo_end_time = elmo_concat_end_time = time.time()\n",
    "print(\"Total concatenation time: {} seconds\".format(elmo_concat_end_time - elmo_concat_start_time))\n",
    "print(\"Total time for ELMo vector extraction: {} seconds\".format(elmo_end_time - elmo_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving output to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out_train = open(\"elmo_faq_train_04062019.pickle\",\"wb\")\n",
    "pickle_out_test = open(\"elmo_faq_test_04062019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_faq_train, pickle_out_train)\n",
    "pickle.dump(elmo_faq_test,pickle_out_test)\n",
    "pickle_out_train.close()\n",
    "pickle_out_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading ELMo vectors pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in_train = open(\"elmo_faq_train_04062019.pickle\",\"rb\")\n",
    "pickle_in_test = open(\"elmo_faq_test_04062019.pickle\",\"rb\")\n",
    "elmo_faq_train = pickle.load(pickle_in_train)\n",
    "elmo_faq_test = pickle.load(pickle_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.DataFrame(elmo_faq_train)\n",
    "ytrain = faq_train['Remarks']\n",
    "xvalid = pd.DataFrame(elmo_faq_test)\n",
    "yvalid = faq_test['Remarks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Linear SVM (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_start_time = time.time()\n",
    "sgdclassifier = SGDClassifier(random_state = 1)\n",
    "sgdclassifier.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_sgd = sgdclassifier.predict(xvalid)\n",
    "sgd_end_time = time.time()\n",
    "print(\"Total time spent on SVM (SGD): {} seconds\".format(sgd_end_time - sgd_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Linear SVM (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear SVM (SGD)\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tuning the SGD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating thorugh the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_list = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss']\n",
    "p_list = ['l1','l2']\n",
    "fi_list = [True, False]\n",
    "mi_list = [500, 1000, 1500]\n",
    "t_list = [0.0001, 0.001]\n",
    "nj_list = [1, 2]\n",
    "lr_list = ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "es_list = [True, False]\n",
    "cw_list = [None, 'balanced']\n",
    "avg_list = [True, False]\n",
    "pr = []\n",
    "r = []\n",
    "f1 = []\n",
    "mcc = []\n",
    "for avg in avg_list:\n",
    "    for cw in cw_list:\n",
    "        for es in es_list:\n",
    "            for lr in lr_list:\n",
    "                for nj in nj_list:\n",
    "                    for t in t_list:\n",
    "                        for mi in mi_list:\n",
    "                            for fi in fi_list:\n",
    "                                for p in p_list:\n",
    "                                    for l in l_list:\n",
    "                                        sgdclassifier = SGDClassifier(random_state = 1, eta0 = 1, loss = l, penalty = p, fit_intercept = fi, max_iter = mi, tol = t, n_jobs = nj, learning_rate = lr, early_stopping = es, class_weight = cw, average = avg)\n",
    "                                        sgdclassifier.fit(xtrain, ytrain)\n",
    "                                        pred_val_sgd = sgdclassifier.predict(xvalid)\n",
    "                                        print(\"SGD with l - {}, p = {}, fi - {}, mi = {}, t = {}, nj = {}, lr - {}, es - {}, cw - {}, avg - {}\".format(l, p, fi, mi, t, nj, lr, es, cw, avg))\n",
    "                                        print(\"Precision: \",precision_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "                                        pr.append(precision_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "                                        print(\"Recall: \",recall_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "                                        r.append(recall_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "                                        print(\"F1 Score: \",f1_score(yvalid, pred_val_sgd,pos_label='FAQ'))\n",
    "                                        f1.append(f1_score(yvalid, pred_val_sgd,pos_label='FAQ'))\n",
    "                                        print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_sgd))\n",
    "                                        mcc.append(matthews_corrcoef(yvalid, pred_val_sgd))\n",
    "                                        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max precision: \",max(pr))\n",
    "print(\"Max recall: \",max(r))\n",
    "print(\"Max F1: \",max(f1))\n",
    "print(\"Max MCC: \",max(mcc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
